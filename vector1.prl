#!/usr/local/bin/perl -w

use strict;

use Carp;
use FileHandle;

##########################################################
##  VECTOR1
##
##  Usage:   vector1     (no command line arguments)
##
##  The function &main_loop below gives the menu for the system.
##########################################################


############################################################
## Program Defaults and Global Variables
############################################################

my $DIR  = "corpus/cnn";
my $HOME = "corpus/cnn";

my $token_docs = "$DIR/cnn";           # tokenized cacm journals
my $corps_freq = "$DIR/cnn";           # frequency of each token in the journ.
my $stoplist   = "$DIR/../common_words";   # common uninteresting words

my $option_term_weighting = "2";
my $option_stemming = "2";
my $option_stopwords = "1";
my $option_region_weighting = "2";

# @doc_vector
#
#   An array of hashes, each array index indicating a particular document's
#   weight "vector". 

my @doc_vector = ( );

# %docs_freq_hash
#
# associative array which holds <token, frequency> pairs where
#
#   token     = a particular word or tag found in the cacm corpus
#   frequency = the total number of times the token appears in
#               the corpus.

my %docs_freq_hash = ( );    

# %corp_freq_hash
#
# associative array which holds <token, frequency> pairs where
#
#   token     = a particular word or tag found in the corpus
#   frequency = the total number of times the token appears per
#               document-- that is a token is counted only once
#               per document if it is present (even if it appears 
#               several times within that document).

my %corp_freq_hash = ( );

# %stoplist_hash
#
# common list of uninteresting words which are likely irrelvant
# to any query.
#
#   Note: this is an associative array to provide fast lookups
#         of these boring words

my %stoplist_hash  = ( );

# START PROGRAM

&main_loop;

##########################################################
##  INIT_FILES
##
##  This function specifies the names and locations of
##  input files used by the program. 
##
##  Parameter:  $type   ("stemmed" or "unstemmed")
##
##  If $type == "stemmed", the filenames are initialized
##  to the versions stemmed with the Porter stemmer, while
##  in the default ("unstemmed") case initializes to files
##  containing raw, unstemmed tokens.
##########################################################

sub init_files {

  if ("stemmed" eq (shift || "")) {

    $token_docs .= "\.stemmed";
    $corps_freq .= "\.stemmed\.hist";
    $stoplist   .= "\.stemmed";
  }
  else {
    $token_docs .= "\.tokenized";
    $corps_freq .= "\.tokenized\.hist";
  }
}

##########################################################
##  INIT_CORP_FREQ 
##
##  This function reads in corpus and document frequencies from
##  the provided histogram file for both the document set
##  and the query set. This information will be used in
##  term weighting.
##
##  It also initializes the arrays representing the stoplist,
##  title list and relevance of document given query.
##########################################################

sub init_corp_freq {

  my $corps_freq_fh = new FileHandle $corps_freq, "r" 
    or croak "Failed $corps_freq";

  my $stoplist_fh   = new FileHandle $stoplist  , "r"
    or croak "Failed $stoplist";

  my $line = undef;

  while (defined( $line = <$corps_freq_fh> )) {

    my ($str) = ($line =~ /^\s*(\S.*)/);

    my ($doc_freq,
        $cor_freq, 
        $term    ) = split /\s+/, $str;

    $docs_freq_hash{ $term } = $doc_freq;
    $corp_freq_hash{ $term } = $cor_freq;
  }


  while (defined( $line = <$stoplist_fh> )) {

    chomp $line;
    $stoplist_hash{ $line } = 1;
  }
}


##########################################################
##  INIT_DOC_VECTORS
##
##  This function reads in tokens from the document file.
##  When a .I token is encountered, indicating a document
##  break, a new vector is begun. When individual terms
##  are encountered, they are added to a running sum of
##  term frequencies. To save time and space, it is possible
##  to normalize these term frequencies by inverse document
##  frequency (or whatever other weighting strategy is
##  being used) while the terms are being summed or in
##  a posthoc pass.  The 2D vector array 
##
##    $doc_vector[ $doc_num ]{ $term }
##
##  stores these normalized term weights.
##########################################################

sub init_doc_vectors {

  my $TITLE_BASE_WEIGHT = 3;     # weight given a title token
    my $KEYWD_BASE_WEIGHT = 4;     # weight given a key word token
    my $ABSTR_BASE_WEIGHT = 1;     # weight given an abstract word token
    my $AUTHR_BASE_WEIGHT = 3;     # weight given an an author token

    my $token_docs_fh = new FileHandle $token_docs, "r"
    or croak "Failed $token_docs";

  my $word    = undef;

  my $doc_num =  0;    # current document number and total docs at end
    my $tweight =  0;    # current weight assigned to document token

    push @doc_vector, { };     # push one empty value onto @doc_vector so that
# indices correspond with document numbers

    while (defined( $word = <$token_docs_fh> )) {

      chomp $word;

      last if $word =~ /^\.I 0/; # indicates end of file so kick out

        if ($word =~ /^\.I/) {     # indicates start of a new document

          push @doc_vector, { };
          $doc_num++;

          next;
        }


# OPTION REGION WEIGHTING CHECK (5)
      if ($option_region_weighting =~ /[1]/) {
        $tweight = $ABSTR_BASE_WEIGHT and next if $word =~ /^\.T/;
        $tweight = $ABSTR_BASE_WEIGHT and next if $word =~ /^\.K/;
        $tweight = $ABSTR_BASE_WEIGHT and next if $word =~ /^\.W/;
        $tweight = $ABSTR_BASE_WEIGHT and next if $word =~ /^\.A/;
      } elsif ($option_region_weighting =~ /[3]/) {
        $tweight = $ABSTR_BASE_WEIGHT and next if $word =~ /^\.T/;
        $tweight = $ABSTR_BASE_WEIGHT and next if $word =~ /^\.K/;
        $tweight = $KEYWD_BASE_WEIGHT and next if $word =~ /^\.W/;
        $tweight = $ABSTR_BASE_WEIGHT and next if $word =~ /^\.A/;
      } else {
        $tweight = $TITLE_BASE_WEIGHT and next if $word =~ /^\.T/;
        $tweight = $KEYWD_BASE_WEIGHT and next if $word =~ /^\.K/;
        $tweight = $ABSTR_BASE_WEIGHT and next if $word =~ /^\.W/;
        $tweight = $AUTHR_BASE_WEIGHT and next if $word =~ /^\.A/;
      }

      if ($word =~ /[a-zA-Z]/ and (! exists $stoplist_hash{ $word } || $option_stopwords =~ /[2]/)) {
        if (defined( $docs_freq_hash{ $word } )) {
# OPTION TERM WEIGHTING (1)
          if ($option_term_weighting =~ /[3]/) {
            $doc_vector[$doc_num]{ $word } = 1;
          } else {
            $doc_vector[$doc_num]{ $word } += $tweight;
          }

        }
        else {
          print "ERROR: Document frequency of zero: ", $word, "\n";
        }
      }
    }

# OPTION TERM WEIGHTING (1)
  if ($option_term_weighting =~ /[2]/) {
    foreach my $hash (@doc_vector) {
      foreach my $key (keys %{ $hash }) {
        if ($doc_num == 0 or $docs_freq_hash{ $key } == 0) {
          $hash->{$key} = 0;
        } else {
          $hash->{$key} *= log( $doc_num / $docs_freq_hash{ $key });
        }
      }
    }
  }

  return $doc_num;
}


##########################################################
## MAIN_LOOP
##
## Parameters: currently no explicit parameters.
##             performance dictated by user imput.
## 
## Initializes document and query vectors using the
## input files specified in &init_files. Then offers
## a menu and switch to appropriate functions in an
## endless loop.
## 
## Possible extensions at this level:  prompt the user
## to specify additional system parameters, such as the
## similarity function to be used.
##
## Currently, the key parameters to the system (stemmed/unstemmed,
## stoplist/no-stoplist, term weighting functions, vector
## similarity functions) are hardwired in.
##
## Initializing the document vectors is clearly the
## most time consuming section of the program, as 213334 
## to 258429 tokens must be processed, weighted and added
## to dynamically growing vectors.
## 
##########################################################

sub main_loop {
  print "\nCHECKING PARAMETERS ...\n";
  &get_params;

  print "INITIALIZING VECTORS ... \n";

# OPTION STEMMING (3)
  if ($option_stemming =~ /[1]/) {
    &init_files ( "unstemmed" );
  } else {
    &init_files ( "stemmed" );
  }

  &init_corp_freq;

  my $total_docs = &init_doc_vectors;

  &write_data("saved.data", $total_docs);
}

sub write_data {
  my $file = shift;
  my $total_docs = shift;

  open OUT, ">$file";

  my %avg_doc_hash = ();
  my %avg_doc_freq_hash = ();

  foreach my $hash (@doc_vector) {
    foreach my $key (keys %{ $hash }) {
      $avg_doc_hash{$key} += $hash->{$key} / $total_docs;
    }
  }

  print OUT scalar(keys(%avg_doc_hash)), "\n";
  foreach my $key (keys %avg_doc_hash) {
    print OUT $key, " ";
    print OUT $avg_doc_hash{$key}, "\n";
  }

  print OUT scalar(keys(%docs_freq_hash)), "\n";
  foreach my $key (keys %docs_freq_hash) {
    print OUT $key, " ";
    print OUT $docs_freq_hash{$key}, "\n";
  }

  print OUT scalar(keys(%corp_freq_hash)), "\n";
  foreach my $key (keys %corp_freq_hash) {
    print OUT $key, " ";
    print OUT $corp_freq_hash{$key}, "\n";
  }

  print OUT scalar(keys(%stoplist_hash)), "\n";
  foreach my $key (keys %stoplist_hash) {
    print OUT $key, " ";
    print OUT $stoplist_hash{$key}, "\n";
  }

  close OUT;
}

sub get_params {
  print << "EndOfMenu";
  Choose a term weighting method
    1. Raw TF
    2. * TF IDF
    3. Boolean

EndOfMenu
    ;
    
  print "Choice: ";

  my    $comp_type = <STDIN>;
  chomp $comp_type;
  if   ($comp_type !~ /^[1-3]$/) { $comp_type = 2; }
  $option_term_weighting = "$comp_type";

  print << "EndOfMenu";
  Choose stemming
    1. Raw, unstemmed
    2. * Porter Stemmer

EndOfMenu
    ;
    
  print "Choice: ";

  $comp_type = <STDIN>;
  chomp $comp_type;
  if   ($comp_type !~ /^[1-3]$/) { $comp_type = 2; }
  $option_stemming = "$comp_type";

  print << "EndOfMenu";
  Choose stopwords
    1. * Exclude Stopwords
    2. Include all tokens

EndOfMenu
    ;
    
  print "Choice: ";

  $comp_type = <STDIN>;
  chomp $comp_type;
  if   ($comp_type !~ /^[1-3]$/) { $comp_type = 1; }
  $option_stopwords = "$comp_type";

  print << "EndOfMenu";
  Choose region weighting
    1. Weight regions equally
    2. * Titles=3x, keywords=4x, author list=3x, abstract=1x
    3. Titles=1x, Keywords=1x, Author List=1x, Abstract=4x

EndOfMenu
    ;
    
  print "Choice: ";

  $comp_type = <STDIN>;
  chomp $comp_type;
  if   ($comp_type !~ /^[1-3]$/) { $comp_type = 2; }
  $option_region_weighting = "$comp_type";

}
